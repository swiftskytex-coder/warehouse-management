#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å snab-lift.ru
"""

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import json
import time

# –°–ø–∏—Å–æ–∫ URL —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
URLS = [
    "https://snab-lift.ru/catalog/zapchasti-k-liftam/postyi-vyizyivnyie-i-moduli/knopki-dlya-liftov-mlz/jhsgqt-knopochnyy-modul-ak1-01-kr-s-markirovkoy-10.html",
    # –î–æ–±–∞–≤—å —Å—é–¥–∞ –¥—Ä—É–≥–∏–µ URL:
    # "https://snab-lift.ru/catalog/.../product2.html",
    # "https://snab-lift.ru/catalog/.../product3.html",
]

def create_driver():
    """–°–æ–∑–¥–∞–µ—Ç headless Chrome"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''Object.defineProperty(navigator, 'webdriver', {get: () => undefined})'''
    })
    
    return driver

def parse_product(driver, url):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É –∫–∞—Ä—Ç–æ—á–∫—É —Ç–æ–≤–∞—Ä–∞"""
    
    try:
        driver.get(url)
        time.sleep(3)
        
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        product_data = {
            'url': url,
            'title': '',
            'price': '',
            'sku': '',
            'description': '',
            'images': [],
            'specifications': {},
            'in_stock': False,
        }
        
        # –ù–∞–∑–≤–∞–Ω–∏–µ
        title_elem = soup.find('h1')
        if title_elem:
            product_data['title'] = title_elem.get_text(strip=True)
        
        # –¶–µ–Ω–∞
        price_selectors = ['.price_value', '.current-price', '.price']
        for selector in price_selectors:
            try:
                price_elem = driver.find_element(By.CSS_SELECTOR, selector)
                if price_elem:
                    product_data['price'] = price_elem.text.strip()
                    break
            except:
                continue
        
        # –ê—Ä—Ç–∏–∫—É–ª
        sku_elem = soup.select_one('.product-article')
        if sku_elem:
            product_data['sku'] = sku_elem.get_text(strip=True)
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        desc_elem = soup.select_one('#prod-desc')
        if desc_elem:
            product_data['description'] = desc_elem.get_text(strip=True)
        
        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        vendor_elem = soup.select_one('.product-sidebar-vendor')
        if vendor_elem:
            vendor_text = vendor_elem.get_text(strip=True)
            if '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å:' in vendor_text:
                product_data['specifications']['–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å'] = vendor_text.replace('–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å:', '').strip()
        
        char_rows = soup.select('.product-sidebar-char')
        for row in char_rows:
            spans = row.find_all('span')
            if len(spans) >= 2:
                key = spans[0].get_text(strip=True).replace(':', '')
                value = spans[1].get_text(strip=True)
                if key and value:
                    product_data['specifications'][key] = value
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img_elems = soup.find_all('img')
        for img in img_elems:
            src = img.get('src') or img.get('data-src')
            if src and any(keyword in src.lower() for keyword in ['products', 'upload']):
                if any(ext in src.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                    if src.startswith('//'):
                        src = 'https:' + src
                    elif src.startswith('/'):
                        src = 'https://snab-lift.ru' + src
                    if src not in product_data['images']:
                        product_data['images'].append(src)
        
        return product_data
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}")
        return None

def main():
    print(f"üöÄ –ü–∞—Ä—Å–∏–Ω–≥ {len(URLS)} —Ç–æ–≤–∞—Ä–æ–≤")
    print("=" * 60)
    
    driver = create_driver()
    all_products = []
    
    try:
        for i, url in enumerate(URLS, 1):
            print(f"\nüì¶ –¢–æ–≤–∞—Ä {i}/{len(URLS)}")
            print(f"üîó {url}")
            
            product = parse_product(driver, url)
            
            if product:
                all_products.append(product)
                print(f"‚úÖ {product['title'][:50]}...")
                print(f"üí∞ {product['price']}")
                print(f"üñºÔ∏è  {len(product['images'])} —Ñ–æ—Ç–æ")
                print(f"üìã {len(product['specifications'])} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—á—Ç–æ–±—ã –Ω–µ –∑–∞–±–∞–Ω–∏–ª–∏)
            if i < len(URLS):
                time.sleep(2)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ç–æ–≤–∞—Ä—ã
        with open('all_products.json', 'w', encoding='utf-8') as f:
            json.dump(all_products, f, ensure_ascii=False, indent=2)
        
        print(f"\n" + "=" * 60)
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")
        print(f"üìÅ –§–∞–π–ª: all_products.json")
        
    finally:
        driver.quit()

if __name__ == "__main__":
    main()
